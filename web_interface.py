#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Flask Webåº”ç”¨ - å°çº¢ä¹¦æœç´¢ç»“æœç®¡ç†ç•Œé¢
æä¾›JSONæ–‡ä»¶ç®¡ç†å’Œæ‰¹é‡è§£æåŠŸèƒ½
"""

from flask import Flask, render_template, jsonify, request
import os
import json
import time
import sys
from datetime import datetime
from pathlib import Path
from xhs_utils.common_util import init
from json_to_full_data import JsonToFullData
from typing import Dict, List, Any
from cookie_pool import cookie_pool, initialize_pool_from_env
from loguru import logger

# é…ç½®æ—¥å¿—è¾“å‡º
logger.remove()  # ç§»é™¤é»˜è®¤handler
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level="INFO"
)
# åˆ›å»ºlogsç›®å½•
os.makedirs("logs", exist_ok=True)
# æ·»åŠ æ–‡ä»¶è¾“å‡º
logger.add(
    "logs/web_interface.log",
    rotation="10 MB",  # æ—¥å¿—æ–‡ä»¶è¾¾åˆ°10MBæ—¶è½®è½¬
    retention="7 days",  # ä¿ç•™7å¤©çš„æ—¥å¿—
    encoding="utf-8",
    level="DEBUG",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
)

logger.info("=" * 60)
logger.info("å°çº¢ä¹¦JSONæ–‡ä»¶ç®¡ç†ç³»ç»Ÿå¯åŠ¨ä¸­...")
logger.info("=" * 60)

app = Flask(__name__)

# ========== å¯åŠ¨æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ==========
def cleanup_temp_files():
    """æ¸…ç†search_resultsç›®å½•ä¸‹çš„ä¸´æ—¶æ–‡ä»¶"""
    try:
        temp_pattern = os.path.join(SEARCH_RESULTS_DIR, 'temp_single_*.json')
        import glob
        temp_files = glob.glob(temp_pattern)

        if temp_files:
            logger.info(f"ğŸ§¹ å‘ç° {len(temp_files)} ä¸ªä¸´æ—¶æ–‡ä»¶ï¼Œå¼€å§‹æ¸…ç†...")
            for temp_file in temp_files:
                try:
                    os.remove(temp_file)
                    logger.info(f"   âœ… å·²åˆ é™¤: {os.path.basename(temp_file)}")
                except Exception as e:
                    logger.warning(f"   âŒ åˆ é™¤å¤±è´¥: {os.path.basename(temp_file)}, é”™è¯¯: {e}")
            logger.info("âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
        else:
            logger.info("âœ… æœªå‘ç°ä¸´æ—¶æ–‡ä»¶")
    except Exception as e:
        logger.error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

# å¯åŠ¨æ—¶æ‰§è¡Œæ¸…ç†
cleanup_temp_files()

# é…ç½®
SEARCH_RESULTS_DIR = "search_results"
TEMPLATES_DIR = "templates"

# åˆå§‹åŒ–ç¯å¢ƒ
cookies_str, base_path = init()
logger.info("ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")

# åˆå§‹åŒ–Cookieæ± 
initialize_pool_from_env()
if not cookie_pool.accounts and cookies_str:
    # å¦‚æœæ± ä¸ºç©ºä½†æœ‰é»˜è®¤Cookieï¼Œæ·»åŠ åˆ°æ± ä¸­
    cookie_pool.add_account(cookies_str, "é»˜è®¤è´¦å·", "ä».envæ–‡ä»¶åŠ è½½")
    logger.info("å·²ä».envæ–‡ä»¶åŠ è½½é»˜è®¤Cookieè´¦å·")
else:
    logger.info(f"Cookieæ± å·²åŠ è½½ {len(cookie_pool.accounts)} ä¸ªè´¦å·")

@app.route('/')
def index():
    """æ¸²æŸ“ä¸»é¡µ"""
    return render_template('json_manager.html')

@app.route('/cookie-pool')
def cookie_pool_page():
    """æ¸²æŸ“Cookieæ± ç®¡ç†é¡µé¢"""
    return render_template('cookie_pool.html')

@app.route('/api/list-json-files')
def list_json_files():
    """è·å–search_resultsç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶ä¿¡æ¯"""
    try:
        files_info = []
        search_dir = Path(SEARCH_RESULTS_DIR)
        
        if not search_dir.exists():
            return jsonify({
                'success': True,
                'files': [],
                'message': 'search_resultsç›®å½•ä¸å­˜åœ¨'
            })
        
        # éå†æ‰€æœ‰JSONæ–‡ä»¶
        for json_file in search_dir.glob('*.json'):
            try:
                file_stat = json_file.stat()
                file_info = {
                    'filename': json_file.name,
                    'size': file_stat.st_size,
                    'created_time': file_stat.st_ctime,
                    'modified_time': file_stat.st_mtime
                }
                
                # å°è¯•è¯»å–æ–‡ä»¶å†…å®¹è·å–æ›´å¤šä¿¡æ¯
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                        # æå–å…³é”®è¯å’Œç¬”è®°æ•°é‡
                        if isinstance(data, dict):
                            file_info['keyword'] = data.get('query', 'æœªçŸ¥')
                            notes = data.get('notes', [])
                            file_info['note_count'] = len(notes)

                            # ç»Ÿè®¡é¢„æœŸè¯„è®ºæ€»æ•°
                            total_expected_comments = 0
                            for note in notes:
                                interact_info = note.get('interact_info', {})
                                comment_count_str = interact_info.get('comment_count', '0')
                                try:
                                    # å°†å­—ç¬¦ä¸²è½¬ä¸ºæ•´æ•°ï¼ˆå»æ‰å¯èƒ½çš„é€—å·ç­‰ï¼‰
                                    comment_count = int(str(comment_count_str).replace(',', ''))
                                    total_expected_comments += comment_count
                                except:
                                    pass
                            file_info['total_expected_comments'] = total_expected_comments

                        elif isinstance(data, list):
                            file_info['note_count'] = len(data)
                            # å°è¯•ä»æ–‡ä»¶åæå–å…³é”®è¯
                            if 'search_' in json_file.name:
                                parts = json_file.stem.split('_')
                                if len(parts) >= 2:
                                    file_info['keyword'] = parts[1]

                            # ç»Ÿè®¡é¢„æœŸè¯„è®ºæ€»æ•°
                            total_expected_comments = 0
                            for note in data:
                                interact_info = note.get('interact_info', {})
                                comment_count_str = interact_info.get('comment_count', '0')
                                try:
                                    comment_count = int(str(comment_count_str).replace(',', ''))
                                    total_expected_comments += comment_count
                                except:
                                    pass
                            file_info['total_expected_comments'] = total_expected_comments
                except:
                    file_info['note_count'] = 0
                    file_info['keyword'] = 'æœªçŸ¥'
                    file_info['total_expected_comments'] = 0
                
                files_info.append(file_info)
                
            except Exception as e:
                logger.warning(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
                continue
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        files_info.sort(key=lambda x: x['created_time'], reverse=True)
        
        return jsonify({
            'success': True,
            'files': files_info,
            'total': len(files_info)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/view-json/<filename>')
def view_json(filename):
    """æŸ¥çœ‹JSONæ–‡ä»¶å†…å®¹"""
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åä¸åŒ…å«è·¯å¾„éå†
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify({
                'success': False,
                'message': 'éæ³•æ–‡ä»¶å'
            }), 400
        
        file_path = Path(SEARCH_RESULTS_DIR) / filename
        
        if not file_path.exists():
            return jsonify({
                'success': False,
                'message': 'æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = json.load(f)
        
        return jsonify({
            'success': True,
            'content': content,
            'filename': filename
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/parse-json', methods=['POST'])
def parse_json():
    """è§£æJSONæ–‡ä»¶å¹¶è·å–å®Œæ•´æ•°æ®"""
    try:
        data = request.json
        files_to_parse = data.get('files', [])
        save_format = data.get('save_format', 'all')
        include_comments = data.get('include_comments', True)
        download_media = data.get('download_media', True)
        output_name = data.get('output_name', '')
        # æ–°å¢å‚æ•°
        min_completion_rate = data.get('min_completion_rate', 0.9)
        force_retry = data.get('force_retry', False)
        resume_incomplete = data.get('resume_incomplete', False)

        logger.info(f"å¼€å§‹è§£æä»»åŠ¡: æ–‡ä»¶æ•°={len(files_to_parse)}, æ ¼å¼={save_format}, è¯„è®º={include_comments}, åª’ä½“={download_media}")

        if not files_to_parse:
            return jsonify({
                'success': False,
                'message': 'æ²¡æœ‰é€‰æ‹©è¦è§£æçš„æ–‡ä»¶'
            }), 400

        # åˆ›å»ºè§£æå™¨å®ä¾‹ï¼Œä¼ å…¥Cookieæ± 
        parser = JsonToFullData(cookie_pool=cookie_pool)
        logger.info(f"è§£æå™¨å·²åˆå§‹åŒ–ï¼ŒCookieæ± çŠ¶æ€: {len(cookie_pool.accounts)} ä¸ªè´¦å·")

        # ç»Ÿè®¡ç»“æœ
        results = {
            'success_count': 0,
            'failed_count': 0,
            'failed_files': [],
            'output_paths': []
        }

        # æ‰¹é‡å¤„ç†æ–‡ä»¶
        for filename in files_to_parse:
            try:
                logger.info(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {filename}")
                json_path = os.path.join(SEARCH_RESULTS_DIR, filename)

                if not os.path.exists(json_path):
                    logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
                    results['failed_count'] += 1
                    results['failed_files'].append({
                        'filename': filename,
                        'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
                    })
                    continue

                # ç”Ÿæˆè¾“å‡ºç›®å½•å
                if output_name:
                    output_dir = output_name
                else:
                    # ä»æ–‡ä»¶åæå–ä¿¡æ¯ä½œä¸ºè¾“å‡ºç›®å½•å
                    base_name = Path(filename).stem
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    output_dir = f"parsed_{base_name}_{timestamp}"

                # æ£€æŸ¥Cookieæ± æ˜¯å¦æœ‰å¯ç”¨è´¦å·
                if len(cookie_pool.accounts) == 0:
                    logger.error(f"Cookieæ± ä¸­æ²¡æœ‰å¯ç”¨è´¦å·")
                    results['failed_count'] += 1
                    results['failed_files'].append({
                        'filename': filename,
                        'error': 'æ²¡æœ‰å¯ç”¨çš„Cookieè´¦å·ï¼Œè¯·æ£€æŸ¥å·æ± '
                    })
                    continue

                logger.info(f"å¼€å§‹è§£ææ–‡ä»¶ï¼ŒCookieæ± å°†è‡ªåŠ¨é‡è¯•æ‰€æœ‰è´¦å·")

                # è°ƒç”¨è§£æå‡½æ•°ï¼ˆå†…éƒ¨ä¼šè‡ªåŠ¨ä½¿ç”¨Cookieæ± é‡è¯•ï¼‰
                try:
                    success, message, stats = parser.process_json_to_full_data(
                        json_file_path=json_path,
                        cookies_str=None,  # ä¸å†éœ€è¦æ‰‹åŠ¨ä¼ Cookieï¼Œç”±Cookieæ± ç®¡ç†
                        output_dir=output_dir,
                        include_comments=include_comments,
                        download_media=download_media,
                        save_format=save_format,
                        min_completion_rate=min_completion_rate,
                        force_retry=force_retry,
                        resume_incomplete=resume_incomplete
                    )

                    if success:
                        notes_count = stats.get('total_notes', 0) if isinstance(stats, dict) else 1
                        comments_count = stats.get('total_comments', 0)
                        logger.info(f"æ–‡ä»¶ {filename} è§£ææˆåŠŸ: å…±{notes_count}æ¡ç¬”è®°, {comments_count}æ¡è¯„è®º")
                    else:
                        logger.error(f"æ–‡ä»¶ {filename} è§£æå¤±è´¥: {message}")

                except Exception as e:
                    logger.error(f"æ–‡ä»¶ {filename} è§£æå¼‚å¸¸: {e}")
                    success = False
                    message = str(e)

                if success:
                    results['success_count'] += 1
                    results['output_paths'].append(output_dir)
                else:
                    results['failed_count'] += 1
                    results['failed_files'].append({
                        'filename': filename,
                        'error': message
                    })
                    
            except Exception as e:
                results['failed_count'] += 1
                results['failed_files'].append({
                    'filename': filename,
                    'error': str(e)
                })

        # è¿”å›ç»“æœ
        logger.info(f"è§£æä»»åŠ¡å®Œæˆ: æˆåŠŸ {results['success_count']} ä¸ª, å¤±è´¥ {results['failed_count']} ä¸ª")
        return jsonify({
            'success': True,
            'results': results,
            'message': f'å¤„ç†å®Œæˆ: æˆåŠŸ {results["success_count"]} ä¸ª, å¤±è´¥ {results["failed_count"]} ä¸ª'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è§£æè¿‡ç¨‹å‡ºé”™: {str(e)}'
        }), 500

@app.route('/api/delete-json', methods=['POST'])
def delete_json():
    """åˆ é™¤JSONæ–‡ä»¶"""
    try:
        data = request.json
        files_to_delete = data.get('files', [])
        
        if not files_to_delete:
            return jsonify({
                'success': False,
                'message': 'æ²¡æœ‰é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶'
            }), 400
        
        deleted_count = 0
        failed_files = []
        
        for filename in files_to_delete:
            try:
                # å®‰å…¨æ£€æŸ¥
                if '..' in filename or '/' in filename or '\\' in filename:
                    failed_files.append({
                        'filename': filename,
                        'error': 'éæ³•æ–‡ä»¶å'
                    })
                    continue
                
                file_path = Path(SEARCH_RESULTS_DIR) / filename
                
                if file_path.exists():
                    file_path.unlink()
                    deleted_count += 1
                else:
                    failed_files.append({
                        'filename': filename,
                        'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
                    })
                    
            except Exception as e:
                failed_files.append({
                    'filename': filename,
                    'error': str(e)
                })
        
        return jsonify({
            'success': True,
            'deleted_count': deleted_count,
            'failed_files': failed_files,
            'message': f'åˆ é™¤å®Œæˆ: æˆåŠŸ {deleted_count} ä¸ª, å¤±è´¥ {len(failed_files)} ä¸ª'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'åˆ é™¤è¿‡ç¨‹å‡ºé”™: {str(e)}'
        }), 500

@app.route('/api/system-info')
def system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    try:
        # ç»Ÿè®¡ä¿¡æ¯
        search_dir = Path(SEARCH_RESULTS_DIR)
        json_files = list(search_dir.glob('*.json')) if search_dir.exists() else []
        
        total_notes = 0
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        notes = data.get('notes', [])
                        total_notes += len(notes)
                    elif isinstance(data, list):
                        total_notes += len(data)
            except:
                continue
        
        return jsonify({
            'success': True,
            'info': {
                'total_json_files': len(json_files),
                'total_notes': total_notes,
                'cookies_configured': bool(cookies_str),
                'base_path': base_path,
                'search_results_dir': str(search_dir.absolute()) if search_dir.exists() else None
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/status')
def get_pool_status():
    """è·å–Cookieæ± çŠ¶æ€"""
    try:
        status = cookie_pool.get_pool_status()
        return jsonify({
            'success': True,
            'data': status
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å·æ± çŠ¶æ€å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/add', methods=['POST'])
def add_cookie():
    """æ·»åŠ Cookieè´¦å·"""
    try:
        data = request.json
        cookie_str = data.get('cookie_str', '')
        name = data.get('name', '')
        remark = data.get('remark', '')

        if not cookie_str:
            return jsonify({
                'success': False,
                'message': 'Cookieä¸èƒ½ä¸ºç©º'
            }), 400

        success = cookie_pool.add_account(cookie_str, name, remark)

        if success:
            logger.info(f"æ·»åŠ Cookieè´¦å·æˆåŠŸ: {name}")
            return jsonify({
                'success': True,
                'message': 'è´¦å·æ·»åŠ æˆåŠŸ'
            })
        else:
            logger.warning(f"æ·»åŠ Cookieè´¦å·å¤±è´¥ (å·²å­˜åœ¨): {name}")
            return jsonify({
                'success': False,
                'message': 'è´¦å·å·²å­˜åœ¨'
            }), 400
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ·»åŠ è´¦å·å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/remove/<cookie_id>', methods=['DELETE'])
def remove_cookie(cookie_id):
    """ç§»é™¤Cookieè´¦å·"""
    try:
        success = cookie_pool.remove_account(cookie_id)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'è´¦å·ç§»é™¤æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'è´¦å·ä¸å­˜åœ¨'
            }), 404
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'ç§»é™¤è´¦å·å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/reset/<cookie_id>', methods=['POST'])
def reset_cookie(cookie_id):
    """é‡ç½®Cookieè´¦å·çŠ¶æ€"""
    try:
        cookie_pool.reset_account(cookie_id)
        return jsonify({
            'success': True,
            'message': 'è´¦å·é‡ç½®æˆåŠŸ'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'é‡ç½®è´¦å·å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/strategy', methods=['POST'])
def set_strategy():
    """è®¾ç½®è½®æ¢ç­–ç•¥"""
    try:
        data = request.json
        strategy = data.get('strategy', 'round_robin')
        
        if strategy not in ['round_robin', 'random', 'least_used']:
            return jsonify({
                'success': False,
                'message': 'æ— æ•ˆçš„ç­–ç•¥ç±»å‹'
            }), 400
        
        cookie_pool.set_strategy(strategy)
        return jsonify({
            'success': True,
            'message': f'ç­–ç•¥å·²è®¾ç½®ä¸º: {strategy}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è®¾ç½®ç­–ç•¥å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/batch-add', methods=['POST'])
def batch_add_cookies():
    """æ‰¹é‡æ·»åŠ Cookie"""
    try:
        data = request.json
        cookies_text = data.get('cookies_text', '')
        
        if not cookies_text:
            return jsonify({
                'success': False,
                'message': 'å†…å®¹ä¸èƒ½ä¸ºç©º'
            }), 400
        
        added_count = 0
        lines = cookies_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            parts = line.split('|')
            if len(parts) == 1:
                cookie_str = parts[0]
                name = None
                remark = ""
            elif len(parts) == 2:
                name, cookie_str = parts
                remark = ""
            else:
                name, cookie_str, remark = parts[:3]
            
            if cookie_pool.add_account(cookie_str.strip(), name, remark):
                added_count += 1
        
        return jsonify({
            'success': True,
            'message': f'æˆåŠŸæ·»åŠ  {added_count} ä¸ªè´¦å·',
            'added_count': added_count
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ‰¹é‡æ·»åŠ å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/settings', methods=['POST'])
def update_pool_settings():
    """æ›´æ–°æ± è®¾ç½®"""
    try:
        data = request.json
        daily_limit = data.get('daily_limit')
        min_interval = data.get('min_interval')
        
        if daily_limit is not None:
            daily_limit = int(daily_limit)
            if daily_limit < 1 or daily_limit > 1000:
                return jsonify({
                    'success': False,
                    'message': 'æ¯æ—¥é™åˆ¶å¿…é¡»åœ¨1-1000ä¹‹é—´'
                }), 400
        
        if min_interval is not None:
            min_interval = int(min_interval)
            if min_interval < 1 or min_interval > 60:
                return jsonify({
                    'success': False,
                    'message': 'æœ€å°é—´éš”å¿…é¡»åœ¨1-60ç§’ä¹‹é—´'
                }), 400
        
        # æ›´æ–°æ‰€æœ‰è´¦å·çš„è®¾ç½®
        cookie_pool.update_all_settings(daily_limit, min_interval)
        
        return jsonify({
            'success': True,
            'message': 'è®¾ç½®å·²ä¿å­˜'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'ä¿å­˜è®¾ç½®å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/cookie-pool/account/<cookie_id>/settings', methods=['POST'])
def update_account_settings(cookie_id):
    """æ›´æ–°å•ä¸ªè´¦å·è®¾ç½®"""
    try:
        data = request.json
        daily_limit = data.get('daily_limit')
        min_interval = data.get('min_interval')

        if daily_limit is not None:
            daily_limit = int(daily_limit)
        if min_interval is not None:
            min_interval = int(min_interval)

        success = cookie_pool.update_account_settings(cookie_id, daily_limit, min_interval)

        if success:
            return jsonify({
                'success': True,
                'message': 'è´¦å·è®¾ç½®å·²æ›´æ–°'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'è´¦å·ä¸å­˜åœ¨'
            }), 404

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ›´æ–°è´¦å·è®¾ç½®å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/list-parsed-dirs')
def list_parsed_dirs():
    """åˆ—å‡ºæ‰€æœ‰å·²è§£æçš„ç›®å½•åŠå…¶è¿›åº¦ä¿¡æ¯"""
    try:
        parsed_dirs = []

        # æŸ¥æ‰¾æ‰€æœ‰parsedå¼€å¤´çš„ç›®å½•
        for item in os.listdir('.'):
            if item.startswith('parsed_') and os.path.isdir(item):
                progress_file = os.path.join(item, 'progress.json')
                dir_info = {
                    'dirname': item,
                    'has_progress': os.path.exists(progress_file),
                    'created_time': os.path.getctime(item)
                }

                # å¦‚æœæœ‰è¿›åº¦æ–‡ä»¶ï¼Œè¯»å–è¿›åº¦ä¿¡æ¯
                if dir_info['has_progress']:
                    try:
                        with open(progress_file, 'r', encoding='utf-8') as f:
                            progress_data = json.load(f)
                            dir_info['progress'] = {
                                'task_id': progress_data.get('task_id'),
                                'json_source': progress_data.get('json_source'),
                                'start_time': progress_data.get('start_time'),
                                'last_update': progress_data.get('last_update'),
                                'total_notes': progress_data.get('total_notes', 0),
                                'statistics': progress_data.get('statistics', {})
                            }
                    except Exception as e:
                        logger.warning(f"è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥: {progress_file}, é”™è¯¯: {e}")
                        dir_info['progress'] = None

                parsed_dirs.append(dir_info)

        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        parsed_dirs.sort(key=lambda x: x['created_time'], reverse=True)

        return jsonify({
            'success': True,
            'directories': parsed_dirs,
            'total': len(parsed_dirs)
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–è§£æç›®å½•åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/list-all-notes')
def list_all_notes():
    """è·å–æ‰€æœ‰JSONæ–‡ä»¶ä¸­çš„ç¬”è®°åŠå…¶è¿›åº¦ä¿¡æ¯"""
    try:
        all_notes = []
        search_dir = Path(SEARCH_RESULTS_DIR)

        if not search_dir.exists():
            return jsonify({
                'success': True,
                'notes': [],
                'message': 'search_resultsç›®å½•ä¸å­˜åœ¨'
            })

        # 1. å…ˆæ”¶é›†æ‰€æœ‰parsedç›®å½•çš„è¿›åº¦ä¿¡æ¯
        progress_data = {}
        for item in os.listdir('.'):
            if item.startswith('parsed_') and os.path.isdir(item):
                progress_file = os.path.join(item, 'progress.json')
                if os.path.exists(progress_file):
                    try:
                        with open(progress_file, 'r', encoding='utf-8') as f:
                            prog = json.load(f)
                            # ä¿å­˜è¿™ä¸ªè¾“å‡ºç›®å½•çš„è¿›åº¦æ•°æ®
                            progress_data[item] = prog
                    except:
                        pass

        # 2. éå†æ‰€æœ‰JSONæ–‡ä»¶ï¼Œæå–ç¬”è®°ä¿¡æ¯
        for json_file in search_dir.glob('*.json'):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # æå–ç¬”è®°åˆ—è¡¨
                notes = []
                if isinstance(data, dict):
                    notes = data.get('notes', [])
                elif isinstance(data, list):
                    notes = data

                # å¤„ç†æ¯ä¸ªç¬”è®°
                for note in notes:
                    note_id = note.get('note_id', '')
                    if not note_id:
                        continue

                    # æå–åŸºæœ¬ä¿¡æ¯
                    title = note.get('title', 'æœªçŸ¥æ ‡é¢˜')
                    note_url = note.get('note_url', '')
                    user_nickname = note.get('user_nickname', '')

                    # æå–é¢„æœŸè¯„è®ºæ•°
                    interact_info = note.get('interact_info', {})
                    expected_comments_str = interact_info.get('comment_count', '0')
                    try:
                        expected_comments = int(str(expected_comments_str).replace(',', ''))
                    except:
                        expected_comments = 0

                    # æŸ¥æ‰¾è¯¥ç¬”è®°çš„è¿›åº¦ä¿¡æ¯ï¼ˆéå†æ‰€æœ‰progress_dataï¼‰
                    fetched_comments = 0
                    status = 'pending'
                    completion_rate = 0
                    output_dir = None
                    last_cursor = ''

                    # å®æ—¶è¿›åº¦ä¿¡æ¯ï¼ˆåˆå§‹åŒ–ï¼‰
                    realtime_progress = {
                        'current_page': 0,
                        'crawl_speed': 0,
                        'latest_error': None,
                        'latest_warning': None
                    }

                    for dir_name, prog in progress_data.items():
                        notes_progress = prog.get('notes_progress', {})
                        if note_id in notes_progress:
                            note_prog = notes_progress[note_id]
                            status = note_prog.get('status', 'pending')
                            comments = note_prog.get('comments', {})
                            fetched_comments = comments.get('total_fetched', 0)
                            last_cursor = comments.get('last_cursor', '')
                            output_dir = dir_name

                            # ========== æå–å®æ—¶è¿›åº¦ä¿¡æ¯ ==========
                            realtime_progress['current_page'] = comments.get('current_page', 0)
                            realtime_progress['crawl_speed'] = comments.get('crawl_speed', 0)

                            # æå–æœ€æ–°çš„é”™è¯¯å’Œè­¦å‘Š
                            errors = comments.get('errors', [])
                            warnings = comments.get('warnings', [])
                            if errors:
                                realtime_progress['latest_error'] = errors[-1].get('message', '')
                            if warnings:
                                realtime_progress['latest_warning'] = warnings[-1].get('message', '')

                            # è®¡ç®—å®Œæˆåº¦
                            if expected_comments > 0:
                                completion_rate = round((fetched_comments / expected_comments) * 100, 1)

                                # æ™ºèƒ½çŠ¶æ€åˆ¤æ–­ï¼šå¦‚æœé¢„æœŸè¯„è®ºæ•°>0ä½†å·²è·å–=0ï¼Œä¸”æ ‡è®°ä¸ºå®Œæˆï¼Œè¯´æ˜æ•°æ®æœ‰é—®é¢˜
                                if status == 'completed' and fetched_comments == 0:
                                    status = 'pending'  # é‡ç½®ä¸ºå¾…å¤„ç†
                                    completion_rate = 0
                                # å¦‚æœè·å–äº†éƒ¨åˆ†è¯„è®ºä½†æœªè¾¾åˆ°100%ï¼ŒçŠ¶æ€åº”è¯¥æ˜¯processing
                                elif status == 'completed' and completion_rate < 100:
                                    status = 'processing'
                            else:
                                completion_rate = 100 if comments.get('completed', False) else 0
                            break

                    # ç»„è£…ç¬”è®°ä¿¡æ¯
                    note_info = {
                        'note_id': note_id,
                        'title': title,
                        'user_nickname': user_nickname,
                        'note_url': note_url,
                        'source_file': json_file.name,
                        'expected_comments': expected_comments,
                        'fetched_comments': fetched_comments,
                        'completion_rate': completion_rate,
                        'status': status,
                        'output_dir': output_dir,
                        'has_cursor': bool(last_cursor),
                        'realtime_progress': realtime_progress  # âœ… æ·»åŠ å®æ—¶è¿›åº¦ä¿¡æ¯
                    }

                    all_notes.append(note_info)

            except Exception as e:
                logger.warning(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
                continue

        # æŒ‰çŠ¶æ€æ’åºï¼šprocessing > failed > pending > completed
        status_order = {'processing': 0, 'failed': 1, 'pending': 2, 'completed': 3}
        all_notes.sort(key=lambda x: (status_order.get(x['status'], 99), x['source_file']))

        return jsonify({
            'success': True,
            'notes': all_notes,
            'total': len(all_notes)
        })

    except Exception as e:
        logger.error(f"è·å–ç¬”è®°åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'message': f'è·å–ç¬”è®°åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/parse-single-note', methods=['POST'])
def parse_single_note():
    """è§£æå•ä¸ªç¬”è®°"""
    try:
        data = request.json
        note_id = data.get('note_id')
        source_file = data.get('source_file')
        include_comments = data.get('include_comments', True)
        download_media = data.get('download_media', True)
        save_format = data.get('save_format', 'all')
        # æ–°å¢å‚æ•°
        min_completion_rate = data.get('min_completion_rate', 0.9)
        force_retry = data.get('force_retry', False)
        resume_incomplete = data.get('resume_incomplete', False)

        logger.info(f"å¼€å§‹è§£æå•ä¸ªç¬”è®°: note_id={note_id}, source_file={source_file}")

        if not note_id or not source_file:
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°: note_id æˆ– source_file'
            }), 400

        # 1. ä»æºæ–‡ä»¶ä¸­è¯»å–ç¬”è®°ä¿¡æ¯
        json_path = os.path.join(SEARCH_RESULTS_DIR, source_file)
        if not os.path.exists(json_path):
            return jsonify({
                'success': False,
                'message': f'æºæ–‡ä»¶ä¸å­˜åœ¨: {source_file}'
            }), 404

        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                file_data = json.load(f)

            # æŸ¥æ‰¾ç›®æ ‡ç¬”è®°
            notes = file_data.get('notes', []) if isinstance(file_data, dict) else file_data
            target_note = None
            for note in notes:
                if note.get('note_id') == note_id:
                    target_note = note
                    break

            if not target_note:
                return jsonify({
                    'success': False,
                    'message': f'åœ¨æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ç¬”è®°: {note_id}'
                }), 404

        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'è¯»å–æºæ–‡ä»¶å¤±è´¥: {str(e)}'
            }), 500

        # 2. ç¡®å®šæˆ–åˆ›å»ºè¾“å‡ºç›®å½•
        # ä¼˜å…ˆæŸ¥æ‰¾æ˜¯å¦å·²æœ‰è¿™ä¸ªç¬”è®°çš„è¿›åº¦
        output_dir = None
        for item in os.listdir('.'):
            if item.startswith('parsed_') and os.path.isdir(item):
                progress_file = os.path.join(item, 'progress.json')
                if os.path.exists(progress_file):
                    try:
                        with open(progress_file, 'r', encoding='utf-8') as f:
                            prog = json.load(f)
                            if note_id in prog.get('notes_progress', {}):
                                output_dir = item
                                logger.info(f"æ‰¾åˆ°ç°æœ‰è¿›åº¦ç›®å½•: {output_dir}")
                                break
                    except:
                        pass

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œåˆ›å»ºæ–°çš„è¾“å‡ºç›®å½•
        if not output_dir:
            base_name = Path(source_file).stem
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = f"parsed_{base_name}_{timestamp}"
            logger.info(f"åˆ›å»ºæ–°çš„è¾“å‡ºç›®å½•: {output_dir}")

        # 3. æ£€æŸ¥Cookieæ± 
        if len(cookie_pool.accounts) == 0:
            return jsonify({
                'success': False,
                'message': 'Cookieæ± ä¸­æ²¡æœ‰å¯ç”¨è´¦å·ï¼Œè¯·å…ˆæ·»åŠ Cookie'
            }), 400

        # 4. âœ¨ ç›´æ¥ä¼ é€’ç¬”è®°æ•°æ®ï¼ˆæ— éœ€åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼‰
        from json_to_full_data import JsonToFullData
        parser = JsonToFullData(cookie_pool=cookie_pool)

        logger.info(f"ğŸ“‹ ç›´æ¥å¤„ç†ç¬”è®°æ•°æ®: {note_id}")

        success, message, stats = parser.process_json_to_full_data(
            note_data_list=[target_note],  # âœ¨ ç›´æ¥ä¼ é€’ç¬”è®°æ•°æ®
            cookies_str=None,  # ä½¿ç”¨Cookieæ± 
            output_dir=output_dir,
            include_comments=include_comments,
            download_media=download_media,
            save_format=save_format,
            min_completion_rate=min_completion_rate,
            force_retry=force_retry,
            resume_incomplete=resume_incomplete
        )

        if success:
            logger.info(f"âœ… å•ç¬”è®°è§£ææˆåŠŸ: {note_id}")
            return jsonify({
                'success': True,
                'message': f'ç¬”è®°è§£ææˆåŠŸ',
                'note_id': note_id,
                'output_dir': output_dir,
                'stats': stats
            })
        else:
            logger.error(f"âŒ å•ç¬”è®°è§£æå¤±è´¥: {note_id}, åŸå› : {message}")
            return jsonify({
                'success': False,
                'message': f'è§£æå¤±è´¥: {message}'
            }), 500

    except Exception as e:
        logger.error(f"è§£æå•ç¬”è®°å¼‚å¸¸: {e}")
        return jsonify({
            'success': False,
            'message': f'è§£æè¿‡ç¨‹å‡ºé”™: {str(e)}'
        }), 500

@app.route('/api/progress/<dirname>')
def get_progress(dirname):
    """è·å–æŒ‡å®šç›®å½•çš„è¿›åº¦è¯¦æƒ…"""
    try:
        # å®‰å…¨æ£€æŸ¥
        if '..' in dirname or '/' in dirname or '\\' in dirname:
            return jsonify({
                'success': False,
                'message': 'éæ³•ç›®å½•å'
            }), 400

        progress_file = os.path.join(dirname, 'progress.json')

        if not os.path.exists(progress_file):
            return jsonify({
                'success': False,
                'message': 'è¿›åº¦æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404

        with open(progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)

        # è¯»å–æºJSONæ–‡ä»¶è·å–çœŸå®çš„é¢„æœŸè¯„è®ºæ•°
        json_source = progress_data.get('json_source', '')
        expected_comments_map = {}  # note_id -> expected_comments

        if json_source and os.path.exists(json_source):
            try:
                with open(json_source, 'r', encoding='utf-8') as f:
                    source_data = json.load(f)
                    source_notes = []
                    if isinstance(source_data, dict):
                        source_notes = source_data.get('notes', [])
                    elif isinstance(source_data, list):
                        source_notes = source_data

                    for note in source_notes:
                        note_id = note.get('note_id', '')
                        interact_info = note.get('interact_info', {})
                        comment_count_str = interact_info.get('comment_count', '0')
                        try:
                            expected_comments_map[note_id] = int(str(comment_count_str).replace(',', ''))
                        except:
                            expected_comments_map[note_id] = 0
            except:
                pass

        # æ•´ç†æ¯ä¸ªç¬”è®°çš„è¿›åº¦ä¿¡æ¯
        notes_progress = progress_data.get('notes_progress', {})
        notes_detail = []

        # é‡æ–°ç»Ÿè®¡çœŸå®çŠ¶æ€
        real_statistics = {
            'completed': 0,
            'failed': 0,
            'processing': 0,
            'pending': 0,
            'skipped': 0
        }

        for note_id, note_info in notes_progress.items():
            # æå–è¯„è®ºè¿›åº¦
            comments = note_info.get('comments', {})
            total_fetched = comments.get('total_fetched', 0)

            # ä½¿ç”¨çœŸå®çš„é¢„æœŸè¯„è®ºæ•°ï¼ˆä¼˜å…ˆä»æºæ–‡ä»¶è¯»å–ï¼‰
            total_expected = expected_comments_map.get(note_id, comments.get('total_expected', 0))

            # è·å–åŸå§‹çŠ¶æ€
            status = note_info.get('status', 'unknown')

            # è®¡ç®—å®Œæˆåº¦
            if total_expected > 0:
                completion_rate = (total_fetched / total_expected) * 100

                # æ™ºèƒ½çŠ¶æ€åˆ¤æ–­ï¼ˆä¸list_all_notesä¿æŒä¸€è‡´ï¼‰
                if status == 'completed' and total_fetched == 0:
                    status = 'pending'  # é‡ç½®ä¸ºå¾…å¤„ç†
                    completion_rate = 0
                elif status == 'completed' and completion_rate < 100:
                    status = 'processing'
            else:
                completion_rate = 100 if comments.get('completed', False) else 0

            # ç»Ÿè®¡çœŸå®çŠ¶æ€
            if status in real_statistics:
                real_statistics[status] += 1

            notes_detail.append({
                'note_id': note_id,
                'note_url': note_info.get('note_url', ''),
                'status': status,  # ä½¿ç”¨ä¿®æ­£åçš„çŠ¶æ€
                'error_message': note_info.get('error_message'),
                'start_time': note_info.get('start_time'),
                'end_time': note_info.get('end_time'),
                'basic_info_saved': note_info.get('basic_info_saved', False),
                'comments': {
                    'enabled': comments.get('enabled', False),
                    'total_expected': total_expected,  # ä½¿ç”¨çœŸå®å€¼
                    'total_fetched': total_fetched,
                    'completion_rate': round(completion_rate, 1),
                    'completed': comments.get('completed', False),
                    'last_cursor': comments.get('last_cursor', '')
                },
                'media': note_info.get('media', {})
            })

        # æŒ‰çŠ¶æ€æ’åºï¼šprocessing > failed > pending > completed
        status_order = {'processing': 0, 'failed': 1, 'pending': 2, 'completed': 3}
        notes_detail.sort(key=lambda x: status_order.get(x['status'], 99))

        # ç”¨ä¿®æ­£åçš„ç»Ÿè®¡æ›¿æ¢åŸå§‹ç»Ÿè®¡
        progress_data['statistics'] = real_statistics

        return jsonify({
            'success': True,
            'progress': progress_data,
            'notes_detail': notes_detail
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è¯»å–è¿›åº¦ä¿¡æ¯å¤±è´¥: {str(e)}'
        }), 500

def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    os.makedirs(SEARCH_RESULTS_DIR, exist_ok=True)
    os.makedirs(TEMPLATES_DIR, exist_ok=True)

    # å¯åŠ¨Flaskåº”ç”¨
    logger.info("=" * 50)
    logger.info("ğŸš€ å°çº¢ä¹¦æœç´¢ç»“æœç®¡ç†ç³»ç»Ÿå¯åŠ¨ä¸­...")
    logger.info("=" * 50)
    logger.info(f"ğŸ“ æœç´¢ç»“æœç›®å½•: {os.path.abspath(SEARCH_RESULTS_DIR)}")
    logger.info(f"ğŸ”§ Cookieé…ç½®çŠ¶æ€: {'å·²é…ç½®' if cookies_str else 'æœªé…ç½®'}")
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: logs/web_interface.log")
    logger.info("=" * 50)
    logger.info("ğŸŒ è®¿é—®åœ°å€: http://localhost:5001")
    logger.info("ğŸ’¡ æç¤º: æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    logger.info("=" * 50)

    app.run(debug=True, host='0.0.0.0', port=5001)

if __name__ == '__main__':
    main()