# encoding: utf-8
"""
è§£æJSONæ–‡ä»¶ï¼Œè·å–ç¬”è®°çš„å®Œæ•´ä¿¡æ¯å¹¶ä¿å­˜
å®ç°æ­¥éª¤2ï¼šè¯»å–JSONæ–‡ä»¶ï¼Œçˆ¬å–å®Œæ•´çš„ç¬”è®°ä¿¡æ¯ï¼ˆåŒ…æ‹¬å›¾ç‰‡ã€è§†é¢‘ã€æ–‡å­—ã€è¯„è®ºï¼‰
"""

import json
import os
import time
import traceback
from datetime import datetime
from loguru import logger
from apis.xhs_pc_apis import XHS_Apis
from xhs_utils.common_util import init
from xhs_utils.data_util import handle_note_info, download_note, handle_comment_info
from progress_manager import ProgressManager


def parse_comment_count(count_str):
    """
    è§£æè¯„è®ºæ•°é‡å­—ç¬¦ä¸²ï¼Œæ”¯æŒä¸­æ–‡"ä¸‡"å’Œè‹±æ–‡"w"

    ç¤ºä¾‹:
    - "2.1ä¸‡" -> 21000
    - "3.5w" -> 35000
    - "1234" -> 1234
    - 1234 -> 1234

    :param count_str: è¯„è®ºæ•°é‡å­—ç¬¦ä¸²æˆ–æ•´æ•°
    :return: æ•´æ•°å½¢å¼çš„è¯„è®ºæ•°é‡
    """
    try:
        # å¦‚æœå·²ç»æ˜¯æ•´æ•°ï¼Œç›´æ¥è¿”å›
        if isinstance(count_str, int):
            return count_str

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè¿›è¡Œè§£æ
        if isinstance(count_str, str):
            count_str = count_str.strip()

            # å¤„ç†åŒ…å«"ä¸‡"çš„æƒ…å†µ
            if 'ä¸‡' in count_str:
                num_str = count_str.replace('ä¸‡', '').strip()
                return int(float(num_str) * 10000)

            # å¤„ç†åŒ…å«"w"æˆ–"W"çš„æƒ…å†µ
            elif 'w' in count_str.lower():
                num_str = count_str.replace('w', '').replace('W', '').strip()
                return int(float(num_str) * 10000)

            # çº¯æ•°å­—å­—ç¬¦ä¸²
            else:
                return int(count_str)

        # å…¶ä»–ç±»å‹è¿”å›0
        return 0
    except Exception as e:
        logger.warning(f"è§£æè¯„è®ºæ•°é‡å¤±è´¥: {count_str}, é”™è¯¯: {e}")
        return 0


class JsonToFullData:
    """
    è§£æJSONæ–‡ä»¶å¹¶è·å–å®Œæ•´ç¬”è®°ä¿¡æ¯çš„ç±»
    """

    def __init__(self, cookie_pool=None):
        """
        åˆå§‹åŒ–ç±»å®ä¾‹

        :param cookie_pool: Cookieæ± å®ä¾‹ï¼Œç”¨äºè‡ªåŠ¨åˆ‡æ¢Cookieé‡è¯•
        """
        self.xhs_apis = XHS_Apis()
        self.cookie_pool = cookie_pool
        self.progress_manager = None  # å°†åœ¨processæ—¶åˆå§‹åŒ–
        
    def parse_json_file(self, json_file_path: str):
        """
        è§£æJSONæ–‡ä»¶ï¼Œæå–ç¬”è®°URLåˆ—è¡¨
        
        :param json_file_path: JSONæ–‡ä»¶è·¯å¾„
        :return: æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, ç¬”è®°URLåˆ—è¡¨
        """
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if 'notes' not in data:
                return False, 'JSONæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘noteså­—æ®µ', []
            
            notes = data['notes']
            note_urls = []
            
            for note in notes:
                if 'note_url' in note:
                    note_urls.append(note['note_url'])
                elif 'note_id' in note and 'xsec_token' in note:
                    # æ ¹æ®note_idå’Œxsec_tokenæ„å»ºURL
                    note_url = f"https://www.xiaohongshu.com/explore/{note['note_id']}?xsec_token={note['xsec_token']}"
                    note_urls.append(note_url)
            
            logger.info(f'ä» {json_file_path} è§£æå‡º {len(note_urls)} ä¸ªç¬”è®°URL')
            return True, f'æˆåŠŸè§£æ {len(note_urls)} ä¸ªç¬”è®°URL', note_urls

        except Exception as e:
            error_msg = f'è§£æJSONæ–‡ä»¶å¤±è´¥: {str(e)}'
            logger.error(error_msg)
            return False, error_msg, []

    def get_with_cookie_pool_retry(self, api_func, *args, **kwargs):
        """
        ä½¿ç”¨Cookieæ± æ‰€æœ‰è´¦å·è¿›è¡Œé‡è¯•
        éå†æ•´ä¸ªæ± ï¼Œåªæœ‰æ‰€æœ‰Cookieéƒ½å¤±è´¥æ‰æ”¾å¼ƒ

        :param api_func: è¦è°ƒç”¨çš„APIæ–¹æ³•
        :param args: APIæ–¹æ³•çš„ä½ç½®å‚æ•°
        :param kwargs: APIæ–¹æ³•çš„å…³é”®å­—å‚æ•°ï¼ˆä¸åŒ…å«cookies_strï¼‰
        :return: success, msg, data, accountï¼ˆä½¿ç”¨çš„è´¦å·ï¼‰
        """
        if not self.cookie_pool:
            # å¦‚æœæ²¡æœ‰Cookieæ± ï¼Œä½¿ç”¨ä¼ å…¥çš„cookies_str
            if 'cookies_str' in kwargs:
                try:
                    success, msg, data = api_func(*args, **kwargs)
                    return success, msg, data, None
                except Exception as e:
                    return False, str(e), None, None
            else:
                return False, "æœªæä¾›Cookieä¸”Cookieæ± ä¸å¯ç”¨", None, None

        tried_cookie_ids = set()  # è®°å½•å·²å°è¯•çš„Cookie ID
        total_accounts = len(self.cookie_pool.accounts)

        if total_accounts == 0:
            logger.error("Cookieæ± ä¸­æ²¡æœ‰å¯ç”¨è´¦å·")
            return False, "Cookieæ± ä¸ºç©º", None, None

        logger.info(f"Cookieæ± å…±æœ‰ {total_accounts} ä¸ªè´¦å·å¯ä¾›é‡è¯•")

        wait_rounds = 0  # ç­‰å¾…è½®æ•°è®¡æ•°å™¨
        max_wait_rounds = 3  # æœ€å¤§ç­‰å¾…è½®æ•°

        while len(tried_cookie_ids) < total_accounts:
            # è·å–å¯ç”¨è´¦å·
            account = self.cookie_pool.get_available_account()

            if not account:
                # å¦‚æœæ²¡æœ‰å¯ç”¨è´¦å·ï¼Œæ£€æŸ¥æ˜¯å¦æ‰€æœ‰è´¦å·éƒ½å·²å°è¯•è¿‡
                if len(tried_cookie_ids) >= total_accounts:
                    logger.error("æ‰€æœ‰Cookieè´¦å·å‡å·²å°è¯•")
                    break

                # å¦‚æœè¿˜æœ‰æœªå°è¯•çš„è´¦å·ï¼Œä½†æš‚æ—¶éƒ½ä¸å¯ç”¨ï¼ˆå¯èƒ½åœ¨å†·å´ä¸­ï¼‰
                if wait_rounds < max_wait_rounds:
                    wait_rounds += 1
                    wait_time = 2  # ç­‰å¾…2ç§’è®©è´¦å·å†·å´
                    logger.warning(f"æ‰€æœ‰è´¦å·æš‚æ—¶ä¸å¯ç”¨ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• (ç¬¬ {wait_rounds}/{max_wait_rounds} è½®)")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"ç­‰å¾… {max_wait_rounds} è½®åä»æ— å¯ç”¨è´¦å·")
                    break

            # è·³è¿‡å·²å°è¯•çš„Cookie
            if account.cookie_id in tried_cookie_ids:
                continue

            tried_cookie_ids.add(account.cookie_id)
            logger.info(f"å°è¯•Cookieè´¦å·: {account.name} ({len(tried_cookie_ids)}/{total_accounts})")

            try:
                # è°ƒç”¨APIï¼Œä¼ å…¥Cookie
                success, msg, data = api_func(*args, cookies_str=account.cookie_str, **kwargs)

                if success:
                    self.cookie_pool.mark_account_success(account.cookie_id)
                    logger.info(f"âœ… Cookie {account.name} è¯·æ±‚æˆåŠŸ")
                    return success, msg, data, account
                else:
                    self.cookie_pool.mark_account_error(account.cookie_id, msg)
                    logger.warning(f"âŒ Cookie {account.name} å¤±è´¥: {msg}ï¼Œåˆ‡æ¢ä¸‹ä¸€ä¸ª")

            except Exception as e:
                self.cookie_pool.mark_account_error(account.cookie_id, str(e))
                logger.warning(f"âŒ Cookie {account.name} å¼‚å¸¸: {e}ï¼Œåˆ‡æ¢ä¸‹ä¸€ä¸ª")

        # æ‰€æœ‰Cookieéƒ½å¤±è´¥
        logger.error(f"æ‰€æœ‰ {total_accounts} ä¸ªCookieè´¦å·å‡å·²å°è¯•å¤±è´¥")
        return False, f"æ‰€æœ‰Cookieè´¦å·({total_accounts}ä¸ª)å‡å¤±è´¥", None, None

    def save_comments_streaming(self, note_id: str, xsec_token: str, output_file: str,
                                expected_comment_count: int = 0, cookies_str: str = None,
                                proxies: dict = None):
        """
        æµå¼è·å–è¯„è®ºï¼Œæ¯é¡µç«‹å³ä¿å­˜åˆ°JSONLæ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
        å¤±è´¥æ—¶éå†æ‰€æœ‰Cookieé‡è¯•

        :param note_id: ç¬”è®°ID
        :param xsec_token: xsec_tokenå‚æ•°
        :param output_file: è¾“å‡ºçš„JSONLæ–‡ä»¶è·¯å¾„
        :param expected_comment_count: é¢„æœŸçš„è¯„è®ºæ€»æ•°ï¼ˆä»ç¬”è®°åŸºæœ¬ä¿¡æ¯è·å–ï¼‰
        :param proxies: ä»£ç†è®¾ç½®
        :return: è·å–åˆ°çš„æ€»è¯„è®ºæ•°
        """
        # ========== æ–­ç‚¹ç»­ä¼ ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„è¿›åº¦ ==========
        resume_cursor = ''
        resume_page = 0
        resume_total = 0

        if self.progress_manager:
            note_progress = self.progress_manager.get_note_progress(note_id)
            comments_progress = note_progress.get('comments', {})

            if comments_progress.get('last_cursor'):
                resume_cursor = comments_progress['last_cursor']
                resume_total = comments_progress.get('total_fetched', 0)
                resume_page = resume_total // 10  # å‡è®¾æ¯é¡µ10æ¡
                logger.info(f"ğŸ”„ æ£€æµ‹åˆ°è¯„è®ºæ–­ç‚¹ï¼Œä»ç¬¬ {resume_page + 1} é¡µç»§ç»­ï¼ˆå·²æœ‰{resume_total}æ¡ï¼‰")

        cursor = resume_cursor
        page = resume_page
        total_comments = resume_total

        # ========== è®¾ç½®é¢„æœŸè¯„è®ºæ€»æ•° ==========
        if self.progress_manager and expected_comment_count > 0:
            logger.info(f"ğŸ“Š è®¾ç½®é¢„æœŸè¯„è®ºæ€»æ•°: {expected_comment_count:,}")
            self.progress_manager.update_comments_progress(
                note_id=note_id,
                total_expected=expected_comment_count
            )

        # åˆ›å»ºæˆ–è¿½åŠ è¯„è®ºæ–‡ä»¶
        file_mode = 'a' if resume_total > 0 else 'w'
        if file_mode == 'w':
            # é¦–æ¬¡è·å–ï¼Œæ¸…ç©ºæ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                pass

        logger.info(f"å¼€å§‹æµå¼è·å–è¯„è®º: note_id={note_id} (ä»cursor={cursor[:20] if cursor else 'å¼€å¤´'})")

        while True:
            page += 1
            # ä¿å­˜å½“å‰é¡µçš„cursorï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
            current_page_cursor = cursor

            # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆå¦‚æœæœ‰é¢„æœŸæ•°é‡ï¼‰
            progress_info = ""
            if expected_comment_count > 0 and total_comments > 0:
                progress_pct = (total_comments / expected_comment_count) * 100
                progress_info = f" | è¿›åº¦: {total_comments:,}/{expected_comment_count:,} ({progress_pct:.1f}%)"

            logger.info(f"ğŸ“„ æ­£åœ¨è·å–ç¬¬ {page} é¡µä¸€çº§è¯„è®º{progress_info}")

            # ========== å®æ—¶æ›´æ–°å½“å‰é¡µæ•° ==========
            if self.progress_manager:
                self.progress_manager.update_comments_progress(
                    note_id=note_id,
                    current_page=page
                )

            # ä½¿ç”¨Cookieæ± å…¨éå†é‡è¯•
            success, msg, res_json, account = self.get_with_cookie_pool_retry(
                self.xhs_apis.get_note_out_comment,
                note_id, cursor, xsec_token,
                proxies=proxies
            )

            if not success:
                error_msg = f"ç¬¬ {page} é¡µè·å–å¤±è´¥ï¼ˆæ‰€æœ‰Cookieå·²å°è¯•ï¼‰: {msg}"
                logger.error(error_msg)
                # ========== è®°å½•é”™è¯¯åˆ°è¿›åº¦ ==========
                if self.progress_manager:
                    self.progress_manager.update_comments_progress(
                        note_id=note_id,
                        error=error_msg
                    )
                break

            # æ£€æŸ¥è¿”å›æ•°æ®ç»“æ„
            if not res_json or 'data' not in res_json:
                warning_msg = f"ç¬¬ {page} é¡µè¿”å›æ•°æ®å¼‚å¸¸ï¼Œåœæ­¢è·å–"
                logger.warning(warning_msg)
                # ========== è®°å½•è­¦å‘Šåˆ°è¿›åº¦ ==========
                if self.progress_manager:
                    self.progress_manager.update_comments_progress(
                        note_id=note_id,
                        warning=warning_msg
                    )
                break

            data = res_json.get('data', {})

            # æ£€æŸ¥æ˜¯å¦æœ‰commentså­—æ®µ
            if 'comments' not in data:
                warning_msg = f"ç¬¬ {page} é¡µè¿”å›dataä¸­æ²¡æœ‰commentså­—æ®µ"
                logger.warning(warning_msg)
                logger.debug(f"è¿”å›æ•°æ®: {res_json}")

                # å¦‚æœæ˜¯ç¬¬1é¡µä¸”dataä¸ºç©ºï¼Œå¾ˆå¯èƒ½æ˜¯xsec_tokenè¿‡æœŸ
                if page == 1 and data == {}:
                    error_msg = "xsec_tokenå·²è¿‡æœŸæˆ–Cookieæƒé™ä¸è¶³ï¼Œè¯„è®ºAPIè¿”å›ç©ºæ•°æ®"
                    logger.error("=" * 60)
                    logger.error("âŒ è¯„è®ºAPIè¿”å›ç©ºæ•°æ®ï¼Œå¯èƒ½åŸå› ï¼š")
                    logger.error("   1. xsec_tokenå·²è¿‡æœŸï¼ˆæœ€å¸¸è§ï¼‰")
                    logger.error("   2. Cookieæƒé™ä¸è¶³")
                    logger.error("   3. ç¬”è®°è¯„è®ºè¢«é™åˆ¶æˆ–å·²åˆ é™¤")
                    logger.error("")
                    logger.error("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
                    logger.error("   â€¢ æ–¹æ¡ˆA: é‡æ–°æœç´¢è¯¥å…³é”®è¯ï¼Œè·å–æ–°çš„ç¬”è®°URL")
                    logger.error("   â€¢ æ–¹æ¡ˆB: æµè§ˆå™¨è®¿é—®ç¬”è®°é¡µé¢ï¼Œå¤åˆ¶æ–°URLï¼ˆåŒ…å«æœ€æ–°xsec_tokenï¼‰")
                    logger.error("   â€¢ æ–¹æ¡ˆC: æ›´æ–°Cookieæ± ä¸­çš„Cookie")
                    logger.error("=" * 60)
                    # ========== è®°å½•é”™è¯¯åˆ°è¿›åº¦ ==========
                    if self.progress_manager:
                        self.progress_manager.update_comments_progress(
                            note_id=note_id,
                            error=error_msg
                        )
                else:
                    # ========== è®°å½•è­¦å‘Šåˆ°è¿›åº¦ ==========
                    if self.progress_manager:
                        self.progress_manager.update_comments_progress(
                            note_id=note_id,
                            warning=warning_msg
                        )
                break

            comments = data['comments']
            has_more = data.get('has_more', False)

            # âœ… å¢é‡ä¿å­˜è¯„è®ºï¼ˆæ¯è·å–ä¸€æ¡å°±ç«‹å³ä¿å­˜ï¼‰
            if comments:
                logger.info(f"ç¬¬ {page} é¡µè·å–åˆ° {len(comments)} æ¡ä¸€çº§è¯„è®ºï¼Œå¼€å§‹å¢é‡è·å–å¹¶ä¿å­˜æ‰€æœ‰å±‚çº§çš„å­è¯„è®º...")

                # å®šä¹‰Cookieæä¾›å‡½æ•°
                def get_cookie_for_comment():
                    """ä¸ºè¯„è®ºè·å–æä¾›Cookieï¼ˆæ”¯æŒCookieæ± å’Œå•Cookieï¼‰"""
                    # ä¼˜å…ˆä½¿ç”¨å½“å‰è¯·æ±‚çš„accountï¼ˆCookieæ± ï¼‰
                    if account and account.cookie_str:
                        return True, account.cookie_str
                    # å…¶æ¬¡å°è¯•ä»Cookieæ± è·å–æ–°è´¦å·
                    elif self.cookie_pool:
                        temp_account = self.cookie_pool.get_available_account()
                        if temp_account:
                            return True, temp_account.cookie_str
                    # æœ€åä½¿ç”¨æä¾›çš„cookies_strï¼ˆå•Cookieæ¨¡å¼ï¼‰
                    elif cookies_str:
                        return True, cookies_str
                    # éƒ½æ²¡æœ‰åˆ™è¿”å›å¤±è´¥
                    logger.error("âŒ æ— å¯ç”¨Cookieï¼šæ—¢æ²¡æœ‰Cookieæ± ä¹Ÿæ²¡æœ‰æä¾›cookies_strå‚æ•°")
                    return False, None

                # åˆ›å»ºå¢é‡ä¿å­˜å›è°ƒå‡½æ•°ï¼ˆæ¯è·å–ä¸€æ¡å­è¯„è®ºå°±ç«‹å³ä¿å­˜ï¼‰
                page_saved_count = 0  # æœ¬é¡µå·²ä¿å­˜çš„è¯„è®ºè®¡æ•°ï¼ˆåŒ…æ‹¬å­è¯„è®ºï¼‰
                last_progress_update = 0  # ä¸Šæ¬¡æ›´æ–°è¿›åº¦æ—¶çš„è¯„è®ºæ•°

                def save_comment_callback(comment_data, level):
                    """
                    å¢é‡ä¿å­˜å•æ¡è¯„è®ºçš„å›è°ƒå‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼šå®æ—¶æ›´æ–°è¿›åº¦ï¼‰
                    :param comment_data: è¯„è®ºæ•°æ®ï¼ˆå·²åŒ…å«_levelå’Œ_parent_idï¼‰
                    :param level: è¯„è®ºå±‚çº§
                    """
                    nonlocal page_saved_count, total_comments, last_progress_update
                    try:
                        # æ·»åŠ note_idå­—æ®µ
                        comment_data['note_id'] = note_id

                        # ç«‹å³è¿½åŠ åˆ°JSONLæ–‡ä»¶
                        with open(output_file, 'a', encoding='utf-8') as f:
                            f.write(json.dumps(comment_data, ensure_ascii=False) + '\n')
                            f.flush()  # ç«‹å³åˆ·æ–°åˆ°ç£ç›˜

                        page_saved_count += 1
                        total_comments += 1

                        # ========== âœ… æ¯50æ¡æ›´æ–°ä¸€æ¬¡è¿›åº¦ï¼ˆå®æ—¶æ€§ï¼‰ ==========
                        if self.progress_manager and (total_comments - last_progress_update) >= 50:
                            self.progress_manager.update_comments_progress(
                                note_id=note_id,
                                total_fetched=total_comments,
                                current_page=page
                            )
                            last_progress_update = total_comments
                            logger.debug(f"    ğŸ”„ å®æ—¶è¿›åº¦å·²æ›´æ–°: {total_comments:,} æ¡è¯„è®º")

                        # æ¯100æ¡æ‰“å°ä¸€æ¬¡è¿›åº¦
                        if page_saved_count % 100 == 0:
                            logger.debug(f"    å·²å¢é‡ä¿å­˜ {page_saved_count} æ¡è¯„è®ºï¼ˆç´¯è®¡: {total_comments:,}ï¼‰")
                    except Exception as e:
                        logger.warning(f"    ä¿å­˜è¯„è®ºå¤±è´¥: {e}")

                # å¤„ç†æ¯æ¡ä¸€çº§è¯„è®ºï¼Œè·å–æ‰€æœ‰å±‚çº§çš„å­è¯„è®º
                for idx, comment in enumerate(comments, 1):
                    # å…ˆä¿å­˜ä¸€çº§è¯„è®ºæœ¬èº«
                    comment['note_id'] = note_id
                    comment['_level'] = 1  # ä¸€çº§è¯„è®º
                    comment['_parent_id'] = ''  # ä¸€çº§è¯„è®ºæ— çˆ¶çº§

                    with open(output_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(comment, ensure_ascii=False) + '\n')
                        f.flush()

                    page_saved_count += 1
                    total_comments += 1

                    # æ£€æŸ¥æ˜¯å¦æœ‰å­è¯„è®º
                    sub_count = comment.get('sub_comment_count', 0)
                    logger.debug(f"  [{idx}/{len(comments)}] è¯„è®º {comment.get('id', 'N/A')[:20]}, sub_comment_count={sub_count}")

                    if isinstance(sub_count, str):
                        sub_count = int(sub_count) if sub_count.isdigit() else 0

                    if sub_count > 0:
                        logger.info(f"  ğŸ’¬ [{idx}/{len(comments)}] è¯„è®ºID: {comment.get('id', 'N/A')[:16]}... | é¢„æœŸå­è¯„è®º: {sub_count:,} æ¡")

                        try:
                            # ä½¿ç”¨æ–°æ–¹æ³•è·å–æ‰€æœ‰å±‚çº§çš„å­è¯„è®ºï¼Œä¼ å…¥ä¿å­˜å›è°ƒ
                            sub_start_time = time.time()
                            success, msg, full_comment = self.xhs_apis.get_note_all_inner_comment_with_provider(
                                comment, xsec_token, get_cookie_for_comment, proxies,
                                level=2, max_level=10,  # æœ€å¤šæ”¯æŒ10å±‚è¯„è®º
                                save_callback=save_comment_callback  # âœ… ä¼ å…¥å¢é‡ä¿å­˜å›è°ƒ
                            )
                            sub_elapsed = time.time() - sub_start_time

                            if success:
                                actual_sub_count = len(full_comment.get('sub_comments', []))
                                logger.info(f"  âœ… å­è¯„è®ºè·å–å®Œæˆ | å®é™…è·å–: {actual_sub_count:,} æ¡ | è€—æ—¶: {sub_elapsed:.1f}ç§’")

                                # å¦‚æœå®é™…è·å–æ•°å°‘äºé¢„æœŸï¼Œå‘å‡ºè­¦å‘Š
                                if actual_sub_count < sub_count * 0.9:  # å…è®¸10%çš„è¯¯å·®
                                    warning_msg = f"å­è¯„è®ºæ•°é‡ä¸è¶³ï¼šé¢„æœŸ{sub_count}æ¡ï¼Œå®é™…{actual_sub_count}æ¡ ({actual_sub_count/sub_count*100:.1f}%)"
                                    logger.warning(f"  âš ï¸ {warning_msg}")
                                    if self.progress_manager:
                                        self.progress_manager.update_comments_progress(
                                            note_id=note_id,
                                            warning=warning_msg
                                        )
                            else:
                                warning_msg = f"å­è¯„è®ºè·å–å¤±è´¥: {msg}"
                                logger.warning(f"  âŒ {warning_msg}")
                                # ========== è®°å½•è­¦å‘Šåˆ°è¿›åº¦ ==========
                                if self.progress_manager:
                                    self.progress_manager.update_comments_progress(
                                        note_id=note_id,
                                        warning=warning_msg
                                    )

                        except Exception as e:
                            warning_msg = f"å¤„ç†è¯„è®ºå¼‚å¸¸: {e}"
                            logger.warning(f"  âš ï¸ {warning_msg}ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€æ¡")
                            # ========== è®°å½•è­¦å‘Šåˆ°è¿›åº¦ ==========
                            if self.progress_manager:
                                self.progress_manager.update_comments_progress(
                                    note_id=note_id,
                                    warning=warning_msg
                                )

                logger.info(f"âœ… ç¬¬ {page} é¡µå·²å¢é‡ä¿å­˜ {page_saved_count} æ¡è¯„è®ºï¼ˆç´¯è®¡: {total_comments}ï¼‰")
            else:
                logger.info(f"ç¬¬ {page} é¡µæ²¡æœ‰è¯„è®ºæ•°æ®ï¼Œåœæ­¢è·å–")
                break

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤š
            if not has_more:
                logger.info(f"has_moreä¸ºFalseï¼Œè¯„è®ºè·å–å®Œæˆ")
                # æ ‡è®°è¯„è®ºè·å–å®Œæˆï¼Œä¿å­˜æœ€åçŠ¶æ€
                if self.progress_manager:
                    self.progress_manager.update_comments_progress(
                        note_id=note_id,
                        total_fetched=total_comments,
                        last_cursor=cursor,  # ä¿å­˜å½“å‰cursorï¼ˆå·²ç»æ˜¯æœ€åä¸€é¡µäº†ï¼‰
                        completed=True
                    )
                break

            # è·å–ä¸‹ä¸€é¡µcursor
            if 'cursor' in data:
                next_cursor = str(data['cursor'])
                logger.debug(f"ä¸‹ä¸€é¡µcursor: {next_cursor}")

                # ========== æ›´æ–°è¯„è®ºè¿›åº¦ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰==========
                # é‡è¦ï¼šåœ¨æˆåŠŸå¤„ç†å®Œå½“å‰é¡µåï¼Œä¿å­˜ä¸‹ä¸€é¡µçš„cursor
                # è¿™æ ·æ–­ç‚¹ç»­ä¼ æ—¶ï¼Œä¼šä»ä¸‹ä¸€é¡µå¼€å§‹ï¼Œä¸ä¼šé‡å¤ä¹Ÿä¸ä¼šä¸¢å¤±æ•°æ®
                if self.progress_manager:
                    self.progress_manager.update_comments_progress(
                        note_id=note_id,
                        total_fetched=total_comments,
                        last_cursor=next_cursor,  # âœ… ä¿å­˜ä¸‹ä¸€é¡µçš„cursorä½œä¸ºæ–­ç‚¹
                        current_page=page
                    )

                # æ›´æ–°cursorä¸ºä¸‹ä¸€é¡µ
                cursor = next_cursor
            else:
                logger.info("æ²¡æœ‰cursorå­—æ®µï¼Œè¯„è®ºè·å–å®Œæˆ")
                # æ ‡è®°è¯„è®ºè·å–å®Œæˆï¼Œä¿å­˜æœ€åçŠ¶æ€
                if self.progress_manager:
                    self.progress_manager.update_comments_progress(
                        note_id=note_id,
                        total_fetched=total_comments,
                        last_cursor=cursor,  # ä¿å­˜æœ€åä¸€ä¸ªcursor
                        completed=True
                    )
                break

            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.5)

        # å¦‚æœå¾ªç¯æ­£å¸¸ç»“æŸï¼ˆä¸æ˜¯breaké€€å‡ºï¼‰ï¼Œè¯´æ˜å¯èƒ½æœ‰å¼‚å¸¸
        # ä¸åº”è¯¥æ— æ¡ä»¶æ ‡è®°ä¸ºå®Œæˆï¼Œå› ä¸ºå¯èƒ½æ˜¯å› ä¸ºé”™è¯¯æå‰é€€å‡º
        logger.info(f"ğŸ“Š è¯„è®ºè·å–ç»“æŸï¼Œå…± {total_comments:,} æ¡è¯„è®ºï¼ˆåŒ…å«æ‰€æœ‰å±‚çº§ï¼‰ä¿å­˜åˆ°: {output_file}")

        # è®¡ç®—å®Œæˆåº¦
        if expected_comment_count > 0:
            completion_pct = (total_comments / expected_comment_count) * 100
            if completion_pct < 50:
                logger.warning(f"âš ï¸ å®Œæˆåº¦è¿‡ä½: {completion_pct:.1f}% ({total_comments:,}/{expected_comment_count:,})")
                logger.warning(f"ğŸ’¡ å¯èƒ½çš„åŸå› ï¼š")
                logger.warning(f"  1. xsec_tokenå·²è¿‡æœŸï¼ˆæœ€å¸¸è§ï¼‰ - éœ€è¦é‡æ–°è·å–URL")
                logger.warning(f"  2. Cookieæƒé™ä¸è¶³æˆ–é™æµ - å°è¯•ä½¿ç”¨Cookieæ± ")
                logger.warning(f"  3. APIè¿”å›has_more=falseä½†å®é™…è¿˜æœ‰æ›´å¤šæ•°æ® - å¯èƒ½æ˜¯å°çº¢ä¹¦çš„é™åˆ¶")
            elif completion_pct < 90:
                logger.info(f"ğŸ“ˆ å®Œæˆåº¦: {completion_pct:.1f}% ({total_comments:,}/{expected_comment_count:,})")
            else:
                logger.success(f"âœ… å®Œæˆåº¦: {completion_pct:.1f}% ({total_comments:,}/{expected_comment_count:,})")

        return total_comments

    def get_note_full_info(self, note_url: str, cookies_str: str = None, output_dir: str = None,
                           proxies: dict = None, include_comments: bool = True):
        """
        è·å–å•ä¸ªç¬”è®°çš„å®Œæ•´ä¿¡æ¯ï¼ˆæ”¯æŒåˆ†æ­¥ä¿å­˜å’ŒCookieæ± é‡è¯•ï¼‰

        :param note_url: ç¬”è®°URL
        :param cookies_str: å°çº¢ä¹¦cookieså­—ç¬¦ä¸²ï¼ˆå¦‚æœä½¿ç”¨Cookieæ± åˆ™å¯é€‰ï¼‰
        :param output_dir: è¾“å‡ºç›®å½•ï¼ˆå¦‚æœæŒ‡å®šåˆ™åˆ†æ­¥ä¿å­˜æ–‡ä»¶ï¼‰
        :param proxies: ä»£ç†è®¾ç½®
        :param include_comments: æ˜¯å¦åŒ…å«è¯„è®ºæ•°æ®
        :return: æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, ç¬”è®°å®Œæ•´ä¿¡æ¯
        """
        try:
            # æ­¥éª¤1: è·å–ç¬”è®°åŸºæœ¬ä¿¡æ¯ï¼ˆä½¿ç”¨Cookieæ± é‡è¯•ï¼‰
            logger.info(f'å¼€å§‹è·å–ç¬”è®°åŸºæœ¬ä¿¡æ¯: {note_url}')

            if self.cookie_pool:
                # ä½¿ç”¨Cookieæ± é‡è¯•
                success, msg, note_info, account = self.get_with_cookie_pool_retry(
                    self.xhs_apis.get_note_info,
                    note_url,
                    proxies=proxies
                )
            else:
                # ç›´æ¥ä½¿ç”¨æä¾›çš„Cookie
                success, msg, note_info = self.xhs_apis.get_note_info(note_url, cookies_str, proxies)
                account = None

            if not success:
                return False, f'è·å–ç¬”è®°ä¿¡æ¯å¤±è´¥: {msg}', None

            # å¤„ç†ç¬”è®°ä¿¡æ¯
            note_info = note_info['data']['items'][0]
            note_info['url'] = note_url
            processed_note = handle_note_info(note_info)
            note_id = processed_note['note_id']

            # æ·»åŠ è·å–æ—¶é—´æˆ³
            processed_note['crawl_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            # âœ… æ­¥éª¤2: ç«‹å³ä¿å­˜åŸºæœ¬ä¿¡æ¯ï¼ˆå¦‚æœæŒ‡å®šäº†output_dirï¼‰
            if output_dir:
                basic_file = os.path.join(output_dir, f"note_{note_id}_basic.json")
                with open(basic_file, 'w', encoding='utf-8') as f:
                    json.dump(processed_note, f, ensure_ascii=False, indent=2)
                logger.info(f"âœ… ç¬”è®°åŸºæœ¬ä¿¡æ¯å·²ä¿å­˜: {basic_file}")

            # æ­¥éª¤3: æµå¼è·å–å’Œä¿å­˜è¯„è®º
            if include_comments:
                try:
                    # æå–xsec_token
                    from urllib.parse import urlparse, parse_qs
                    parsed = urlparse(note_url)
                    query_params = parse_qs(parsed.query)
                    xsec_token = query_params.get('xsec_token', [''])[0]

                    if not xsec_token:
                        logger.error(f"âŒ URLä¸­æ²¡æœ‰xsec_tokenå‚æ•°ï¼Œæ— æ³•è·å–è¯„è®º")
                        logger.error(f"å»ºè®®ï¼šé‡æ–°æœç´¢å…³é”®è¯æˆ–è®¿é—®ç¬”è®°é¡µé¢è·å–æ–°URL")
                        processed_note['comments'] = []
                        processed_note['comment_count'] = 0
                        return True, 'ç¬”è®°åŸºæœ¬ä¿¡æ¯è·å–æˆåŠŸï¼Œä½†ç¼ºå°‘xsec_tokenæ— æ³•è·å–è¯„è®º', processed_note

                    if output_dir:
                        # è§£æé¢„æœŸçš„è¯„è®ºæ€»æ•°
                        expected_count = parse_comment_count(processed_note.get('comment_count', 0))
                        logger.info(f"ğŸ“Š ç¬”è®°æ˜¾ç¤ºè¯„è®ºæ•°: {processed_note.get('comment_count', 'æœªçŸ¥')}, è§£æä¸º: {expected_count:,}")

                        # ç¡®å®šä½¿ç”¨çš„cookieï¼ˆä¼˜å…ˆä½¿ç”¨accountçš„cookieï¼Œå¦åˆ™ä½¿ç”¨ä¼ å…¥çš„cookies_strï¼‰
                        cookie_to_use = account.cookie_str if account and hasattr(account, 'cookie_str') else cookies_str

                        # æµå¼ä¿å­˜åˆ°JSONLæ–‡ä»¶
                        comments_file = os.path.join(output_dir, f"note_{note_id}_comments.jsonl")
                        total_comments = self.save_comments_streaming(
                            note_id, xsec_token, comments_file,
                            expected_comment_count=expected_count,  # âœ… ä¼ é€’é¢„æœŸè¯„è®ºæ•°
                            cookies_str=cookie_to_use,  # âœ… ä¼ é€’Cookieå­—ç¬¦ä¸²
                            proxies=proxies
                        )
                        processed_note['comment_count'] = total_comments
                        processed_note['comments_file'] = comments_file
                        logger.info(f"âœ… è¯„è®ºæ•°æ®å·²ä¿å­˜: {comments_file} (å…±{total_comments}æ¡)")
                    else:
                        # å…¼å®¹æ—§æ¨¡å¼ï¼šå†…å­˜ä¸­è·å–è¯„è®º
                        logger.info(f'è·å–è¯„è®ºæ•°æ®ï¼ˆæ—§æ¨¡å¼ï¼‰: {note_url}')
                        if self.cookie_pool:
                            success, msg, comments, account = self.get_with_cookie_pool_retry(
                                self.xhs_apis.get_note_all_comment,
                                note_url,
                                proxies=proxies
                            )
                        else:
                            success, msg, comments = self.xhs_apis.get_note_all_comment(
                                note_url, cookies_str, proxies
                            )

                        if success and comments:
                            processed_note['comments'] = comments
                            logger.info(f'è·å–è¯„è®ºæ•°æ®æˆåŠŸï¼Œå…± {len(comments)} æ¡è¯„è®º')
                        else:
                            processed_note['comments'] = []
                            logger.warning(f'è·å–è¯„è®ºæ•°æ®å¤±è´¥: {msg}')

                except Exception as e:
                    processed_note['comments'] = []
                    processed_note['comment_count'] = 0
                    logger.warning(f'è·å–è¯„è®ºæ•°æ®å¼‚å¸¸: {str(e)}')
            else:
                processed_note['comments'] = []
                processed_note['comment_count'] = 0

            # âœ… æ­¥éª¤4: ä¿å­˜æˆ–æ›´æ–°å®Œæ•´ä¿¡æ¯JSONï¼ˆå¦‚æœæŒ‡å®šäº†output_dirï¼‰
            if output_dir:
                full_file = os.path.join(output_dir, f"note_{note_id}_full.json")
                with open(full_file, 'w', encoding='utf-8') as f:
                    json.dump(processed_note, f, ensure_ascii=False, indent=2)
                logger.info(f"âœ… ç¬”è®°å®Œæ•´ä¿¡æ¯å·²ä¿å­˜: {full_file}")

            return True, 'è·å–ç¬”è®°å®Œæ•´ä¿¡æ¯æˆåŠŸ', processed_note

        except Exception as e:
            error_msg = f'è·å–ç¬”è®°å®Œæ•´ä¿¡æ¯å¤±è´¥: {str(e)}'
            logger.error(error_msg)
            logger.debug(traceback.format_exc())
            return False, error_msg, None
    
    def process_json_to_full_data(self, json_file_path: str = None, cookies_str: str = None,
                                 output_dir: str = None, include_comments: bool = True,
                                 download_media: bool = True, save_format: str = 'json',
                                 proxies: dict = None, note_data_list: list = None):
        """
        å¤„ç†JSONæ–‡ä»¶æˆ–ç¬”è®°æ•°æ®åˆ—è¡¨ï¼Œè·å–æ‰€æœ‰ç¬”è®°çš„å®Œæ•´ä¿¡æ¯å¹¶ä¿å­˜

        :param json_file_path: è¾“å…¥çš„JSONæ–‡ä»¶è·¯å¾„ï¼ˆä¸note_data_listäºŒé€‰ä¸€ï¼‰
        :param cookies_str: å°çº¢ä¹¦cookieså­—ç¬¦ä¸²ï¼ˆä½¿ç”¨Cookieæ± æ—¶å¯é€‰ï¼‰
        :param output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆ
        :param include_comments: æ˜¯å¦åŒ…å«è¯„è®ºæ•°æ®
        :param download_media: æ˜¯å¦ä¸‹è½½åª’ä½“æ–‡ä»¶ï¼ˆå›¾ç‰‡ã€è§†é¢‘ï¼‰
        :param save_format: ä¿å­˜æ ¼å¼ 'json', 'excel', 'all'
        :param proxies: ä»£ç†è®¾ç½®
        :param note_data_list: ç›´æ¥ä¼ å…¥ç¬”è®°æ•°æ®åˆ—è¡¨ï¼ˆä¸json_file_pathäºŒé€‰ä¸€ï¼‰âœ¨æ–°å¢
        :return: æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, å¤„ç†ç»“æœç»Ÿè®¡
        """
        try:
            # ========== âœ¨ æ–°å¢ï¼šæ”¯æŒç›´æ¥ä¼ å…¥ç¬”è®°æ•°æ® ==========
            if note_data_list is not None:
                # ä»ç¬”è®°æ•°æ®ä¸­æå–URLåˆ—è¡¨
                note_urls = []
                for note in note_data_list:
                    if 'note_url' in note:
                        note_urls.append(note['note_url'])
                    elif 'note_id' in note and 'xsec_token' in note:
                        note_url = f"https://www.xiaohongshu.com/explore/{note['note_id']}?xsec_token={note['xsec_token']}"
                        note_urls.append(note_url)

                if not note_urls:
                    return False, 'ç¬”è®°æ•°æ®ä¸­æ²¡æœ‰æœ‰æ•ˆçš„URL', {}

                # ä½¿ç”¨ç¬”è®°æ•°æ®ä½œä¸ºæ¥æºæ ‡è¯†
                json_source = f"direct_data_{len(note_urls)}_notes"
                logger.info(f'ç›´æ¥å¤„ç† {len(note_urls)} ä¸ªç¬”è®°æ•°æ®ï¼ˆæ— éœ€JSONæ–‡ä»¶ï¼‰')

            elif json_file_path is not None:
                # ä¼ ç»Ÿæ–¹å¼ï¼šè§£æJSONæ–‡ä»¶
                parse_success, parse_msg, note_urls = self.parse_json_file(json_file_path)
                if not parse_success:
                    return False, parse_msg, {}
                json_source = json_file_path

            else:
                return False, 'å¿…é¡»æä¾› json_file_path æˆ– note_data_list å‚æ•°ä¹‹ä¸€', {}
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            if output_dir is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                if json_file_path:
                    json_filename = os.path.splitext(os.path.basename(json_file_path))[0]
                    output_dir = f"parsed_{json_filename}_{timestamp}"
                else:
                    output_dir = f"parsed_direct_data_{timestamp}"

            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ========== åˆå§‹åŒ–è¿›åº¦ç®¡ç†å™¨ï¼ˆæ”¯æŒæ–­ç‚¹ç»­çˆ¬ï¼‰==========
            self.progress_manager = ProgressManager(output_dir, json_source)

            # è·å–å¾…å¤„ç†ç¬”è®°åˆ—è¡¨ï¼ˆè‡ªåŠ¨è·³è¿‡å·²å®Œæˆï¼‰
            pending_note_urls = self.progress_manager.get_pending_notes(note_urls)

            if len(pending_note_urls) == 0:
                logger.success("ğŸ‰ æ‰€æœ‰ç¬”è®°å·²å¤„ç†å®Œæˆï¼")
                # è¯»å–æ±‡æ€»æ•°æ®è¿”å›
                summary_file = os.path.join(output_dir, "summary_all_notes.json")
                if os.path.exists(summary_file):
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        summary_data = json.load(f)
                    result_stats = {
                        'total_notes': len(note_urls),
                        'successful_notes': summary_data['process_info']['successful_notes'],
                        'failed_notes': summary_data['process_info']['failed_notes'],
                        'total_comments': summary_data['process_info']['total_comments'],
                        'output_directory': output_dir
                    }
                    return True, 'æ‰€æœ‰ç¬”è®°å·²å®Œæˆ', result_stats
                else:
                    return True, 'æ‰€æœ‰ç¬”è®°å·²å®Œæˆ', {}

            # åˆ›å»ºåª’ä½“æ–‡ä»¶ç›®å½•
            if download_media:
                media_dir = os.path.join(output_dir, "media_files")
                if not os.path.exists(media_dir):
                    os.makedirs(media_dir)

            # å¤„ç†æ¯ä¸ªç¬”è®°
            successful_notes = []
            failed_notes = []
            total_comments_count = 0

            # è®°å½•å¼€å§‹æ—¶é—´ï¼ˆç”¨äºä¼°ç®—å‰©ä½™æ—¶é—´ï¼‰
            process_start_time = time.time()

            for i, note_url in enumerate(pending_note_urls, 1):
                note_id = None
                try:
                    # ========== æ˜¾ç¤ºè¯¦ç»†è¿›åº¦ ==========
                    elapsed = time.time() - process_start_time
                    remaining_time = self.progress_manager.estimate_remaining_time(i - 1, elapsed)
                    stats = self.progress_manager.get_statistics()

                    progress_msg = (
                        f"\n{'='*60}\n"
                        f"[{i}/{len(pending_note_urls)}] æ€»è¿›åº¦: {stats['completed']}/{len(note_urls)} "
                        f"({stats['completed']/len(note_urls)*100:.1f}%)\n"
                        f"æˆåŠŸ: {stats['completed']} | å¤±è´¥: {stats['failed']} | "
                        f"å‰©ä½™: {stats['pending']} | é¢„è®¡å‰©ä½™æ—¶é—´: {remaining_time}\n"
                        f"{'='*60}"
                    )
                    logger.info(progress_msg)

                    # ========== æ ‡è®°ç¬”è®°å¼€å§‹å¤„ç† ==========
                    note_id = self.progress_manager.extract_note_id(note_url)
                    if note_id:
                        self.progress_manager.mark_note_processing(note_id, note_url)

                    logger.info(f'æ­£åœ¨å¤„ç†ç¬”è®°: {note_url}')

                    # ä½¿ç”¨æ–°çš„åˆ†æ­¥ä¿å­˜æ–¹æ³•
                    success, msg, full_note_info = self.get_note_full_info(
                        note_url,
                        cookies_str=cookies_str,
                        output_dir=output_dir,  # ä¼ é€’output_dirå¯ç”¨åˆ†æ­¥ä¿å­˜
                        proxies=proxies,
                        include_comments=include_comments
                    )

                    if success and full_note_info:
                        successful_notes.append(full_note_info)

                        # ç»Ÿè®¡è¯„è®ºæ•°
                        comment_count = full_note_info.get('comment_count', 0)
                        total_comments_count += comment_count

                        # ä¸‹è½½åª’ä½“æ–‡ä»¶
                        if download_media:
                            try:
                                download_note(full_note_info, media_dir, 'media')
                                logger.info(f'åª’ä½“æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {full_note_info["title"]}')
                            except Exception as e:
                                logger.warning(f'åª’ä½“æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}')

                        # ========== æ ‡è®°ç¬”è®°å®Œæˆ ==========
                        if note_id:
                            details = {
                                'comments': {
                                    'enabled': include_comments,
                                    'total_fetched': comment_count,
                                    'completed': True
                                },
                                'media': {
                                    'enabled': download_media,
                                    'completed': True
                                }
                            }
                            self.progress_manager.mark_note_completed(note_id, details)

                        # æ³¨æ„ï¼šå•ä¸ªç¬”è®°çš„JSONæ–‡ä»¶å·²ç»åœ¨get_note_full_infoä¸­ä¿å­˜ï¼Œæ— éœ€é‡å¤ä¿å­˜
                    else:
                        failed_notes.append({
                            'url': note_url,
                            'error': msg,
                            'note_id': note_id
                        })
                        logger.error(f'å¤„ç†å¤±è´¥: {msg}')

                        # ========== æ ‡è®°ç¬”è®°å¤±è´¥ ==========
                        if note_id:
                            self.progress_manager.mark_note_failed(note_id, msg)

                except Exception as e:
                    # ========== æ•è·ä»»ä½•æœªé¢„æœŸçš„å¼‚å¸¸ï¼Œç¡®ä¿ä¸ä¸­æ–­æ•´ä¸ªæ‰¹å¤„ç† ==========
                    error_msg = f'å¤„ç†ç¬”è®°æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}'
                    logger.error(error_msg)
                    logger.debug(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")

                    failed_notes.append({
                        'url': note_url,
                        'error': error_msg,
                        'note_id': note_id,
                        'exception': True
                    })

                    # æ ‡è®°ç¬”è®°å¤±è´¥
                    if note_id:
                        try:
                            self.progress_manager.mark_note_failed(note_id, error_msg)
                        except Exception as mark_error:
                            logger.warning(f"æ ‡è®°ç¬”è®°å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {mark_error}")

                    # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªç¬”è®°
                    logger.info("â­ï¸  è·³è¿‡å½“å‰ç¬”è®°ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª...")
            
            # ä¿å­˜æ±‡æ€»æ•°æ®
            summary_data = {
                'process_info': {
                    'source_json': json_file_path,
                    'total_notes': len(note_urls),
                    'successful_notes': len(successful_notes),
                    'failed_notes': len(failed_notes),
                    'total_comments': total_comments_count,
                    'include_comments': include_comments,
                    'download_media': download_media,
                    'process_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'comment_storage': 'JSONL files (*.jsonl)' if include_comments else 'None'
                },
                'successful_notes': successful_notes,
                'failed_notes': failed_notes
            }

            # ä¿å­˜æ±‡æ€»JSONæ–‡ä»¶
            if save_format in ['json', 'all']:
                summary_file = os.path.join(output_dir, "summary_all_notes.json")
                with open(summary_file, 'w', encoding='utf-8') as f:
                    json.dump(summary_data, f, ensure_ascii=False, indent=2)
                logger.success(f'æ±‡æ€»JSONæ–‡ä»¶ä¿å­˜åˆ°: {summary_file}')

            # ä¿å­˜ä¸ºExcelæ ¼å¼
            if save_format in ['excel', 'all']:
                from xhs_utils.data_util import save_to_xlsx

                # ä¿å­˜ç¬”è®°æ•°æ®åˆ°Excel
                if successful_notes:
                    excel_file = os.path.join(output_dir, "notes_data.xlsx")
                    save_to_xlsx(successful_notes, excel_file)
                    logger.success(f'ç¬”è®°Excelæ–‡ä»¶ä¿å­˜åˆ°: {excel_file}')

                # æ³¨æ„ï¼šè¯„è®ºæ•°æ®å·²ä¿å­˜ä¸ºJSONLæ ¼å¼ï¼Œä¸å†è‡ªåŠ¨è½¬æ¢ä¸ºExcel
                # å¦‚éœ€Excelæ ¼å¼ï¼Œå¯æ‰‹åŠ¨è¯»å–JSONLæ–‡ä»¶è½¬æ¢
                if include_comments and total_comments_count > 0:
                    logger.info(f'è¯„è®ºæ•°æ®å·²ä¿å­˜ä¸ºJSONLæ ¼å¼ï¼ˆæ¯ä¸ªç¬”è®°ä¸€ä¸ªæ–‡ä»¶ï¼‰ï¼Œå…± {total_comments_count} æ¡è¯„è®º')
                    logger.info(f'JSONLæ–‡ä»¶ä½ç½®: {output_dir}/note_*_comments.jsonl')
            
            # ä¿å­˜å¤„ç†ç»“æœç»Ÿè®¡
            result_stats = {
                'total_notes': len(note_urls),
                'successful_notes': len(successful_notes),
                'failed_notes': len(failed_notes),
                'success_rate': len(successful_notes) / len(note_urls) * 100 if note_urls else 0,
                'total_comments': total_comments_count,
                'output_directory': output_dir
            }

            logger.success(f'å¤„ç†å®Œæˆï¼æˆåŠŸ: {len(successful_notes)}, å¤±è´¥: {len(failed_notes)}, è¯„è®º: {total_comments_count}æ¡')
            logger.success(f'ç»“æœä¿å­˜åˆ°ç›®å½•: {output_dir}')

            return True, 'å¤„ç†å®Œæˆ', result_stats
            
        except Exception as e:
            error_msg = f'å¤„ç†JSONæ–‡ä»¶å¤±è´¥: {str(e)}'
            logger.error(error_msg)
            return False, error_msg, {}
    
    def batch_process_json_files(self, json_files: list, cookies_str: str, 
                               output_base_dir: str = "batch_full_data", **kwargs):
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªJSONæ–‡ä»¶
        
        :param json_files: JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        :param cookies_str: å°çº¢ä¹¦cookieså­—ç¬¦ä¸²
        :param output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
        :param kwargs: å…¶ä»–å¤„ç†å‚æ•°
        :return: æ‰¹é‡å¤„ç†ç»“æœ
        """
        if not os.path.exists(output_base_dir):
            os.makedirs(output_base_dir)
        
        batch_results = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for json_file in json_files:
            logger.info(f'å¼€å§‹å¤„ç†JSONæ–‡ä»¶: {json_file}')
            
            # ä¸ºæ¯ä¸ªJSONæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
            json_name = os.path.splitext(os.path.basename(json_file))[0]
            output_dir = os.path.join(output_base_dir, f"{json_name}_{timestamp}")
            
            success, msg, stats = self.process_json_to_full_data(
                json_file, cookies_str, output_dir, **kwargs
            )
            
            batch_results.append({
                'json_file': json_file,
                'success': success,
                'message': msg,
                'stats': stats,
                'output_dir': output_dir if success else None
            })
        
        # ä¿å­˜æ‰¹é‡å¤„ç†æ±‡æ€»ç»“æœ
        batch_summary = {
            'batch_info': {
                'total_files': len(json_files),
                'successful_files': len([r for r in batch_results if r['success']]),
                'total_notes_processed': sum([r['stats'].get('total_notes', 0) for r in batch_results]),
                'total_successful_notes': sum([r['stats'].get('successful_notes', 0) for r in batch_results]),
                'process_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            'results': batch_results
        }
        
        batch_summary_file = os.path.join(output_base_dir, f"batch_summary_{timestamp}.json")
        with open(batch_summary_file, 'w', encoding='utf-8') as f:
            json.dump(batch_summary, f, ensure_ascii=False, indent=2)
        
        logger.success(f'æ‰¹é‡å¤„ç†å®Œæˆï¼Œæ±‡æ€»ç»“æœä¿å­˜åˆ°: {batch_summary_file}')
        return batch_results


if __name__ == '__main__':
    """
    è§£æJSONæ–‡ä»¶å¹¶è·å–å®Œæ•´ç¬”è®°ä¿¡æ¯çš„ç¤ºä¾‹ä½¿ç”¨
    """
    # åˆå§‹åŒ–é…ç½®
    cookies_str, base_path = init()
    json_processor = JsonToFullData()
    
    # ç¤ºä¾‹ï¼šå¤„ç†å•ä¸ªJSONæ–‡ä»¶
    json_file_path = "search_results/search_æ—¥æœ¬æ–™ç†_20250905_183800.json"  # è¯·ä¿®æ”¹ä¸ºå®é™…æ–‡ä»¶è·¯å¾„
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(json_file_path):
        success, msg, stats = json_processor.process_json_to_full_data(
            json_file_path=json_file_path,
            cookies_str=cookies_str,
            include_comments=True,  # åŒ…å«è¯„è®ºæ•°æ®
            download_media=True,    # ä¸‹è½½åª’ä½“æ–‡ä»¶
            save_format='all'       # ä¿å­˜ä¸ºJSONå’ŒExcelæ ¼å¼
        )
        
        if success:
            print(f"âœ… å¤„ç†æˆåŠŸ: {msg}")
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: {stats}")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {msg}")
    else:
        print(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        print("è¯·å…ˆè¿è¡Œ search_to_json.py ç”ŸæˆJSONæ–‡ä»¶")
    
    # æ‰¹é‡å¤„ç†ç¤ºä¾‹ï¼ˆæ³¨é‡Šæ‰ï¼Œéœ€è¦æ—¶å¯ç”¨ï¼‰
    """
    json_files = [
        "search_results/search_æ—¥æœ¬æ–™ç†_20240101_120000.json",
        "search_results/search_æ„å¤§åˆ©é¢_20240101_120000.json"
    ]
    
    existing_files = [f for f in json_files if os.path.exists(f)]
    if existing_files:
        results = json_processor.batch_process_json_files(
            json_files=existing_files,
            cookies_str=cookies_str,
            include_comments=True,
            download_media=True,
            save_format='all'
        )
        
        for result in results:
            status = "âœ…" if result['success'] else "âŒ"
            file_name = os.path.basename(result['json_file'])
            print(f"{status} {file_name}: {result['message']}")
    """